{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# YOLOv8n Training on Kaggle - Roboflow Dataset\n",
                "\n",
                "Training YOLOv8n model using dataset from Roboflow Universe.\n",
                "\n",
                "**Dataset**: [v5-j3ysc](https://universe.roboflow.com/quang-linh/v5-j3ysc/dataset/1)\n",
                "\n",
                "## Setup Requirements\n",
                "1. Enable GPU in Kaggle (Settings â†’ Accelerator â†’ GPU P100)\n",
                "2. Get your Roboflow API key from [Roboflow Settings](https://app.roboflow.com/settings/api)\n",
                "3. Run all cells sequentially"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install -q ultralytics roboflow\n",
                "\n",
                "print(\"âœ“ Packages installed successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import os\n",
                "import yaml\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "from ultralytics import YOLO\n",
                "from roboflow import Roboflow\n",
                "import torch\n",
                "import glob\n",
                "from IPython.display import Image, display\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"CUDA version: {torch.version.cuda}\")\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download Dataset from Roboflow\n",
                "\n",
                "### Get your API key:\n",
                "1. Go to [Roboflow Settings](https://app.roboflow.com/settings/api)\n",
                "2. Copy your Private API Key\n",
                "3. Paste it in the cell below"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# âš ï¸ IMPORTANT: Replace with your Roboflow API key\n",
                "ROBOFLOW_API_KEY = \"ZibH2Daoysfb8ESqVkWk\"  # Get from https://app.roboflow.com/settings/api\n",
                "\n",
                "# Dataset information\n",
                "WORKSPACE = \"quang-linh\"\n",
                "PROJECT = \"v5-j3ysc\"\n",
                "VERSION = 1\n",
                "\n",
                "print(f\"Workspace: {WORKSPACE}\")\n",
                "print(f\"Project: {PROJECT}\")\n",
                "print(f\"Version: {VERSION}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Roboflow and download dataset\n",
                "print(\"Connecting to Roboflow...\")\n",
                "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
                "\n",
                "print(f\"Downloading dataset: {WORKSPACE}/{PROJECT}...\")\n",
                "project = rf.workspace(WORKSPACE).project(PROJECT)\n",
                "dataset = project.version(VERSION).download(\"yolov8\")\n",
                "\n",
                "DATASET_PATH = dataset.location\n",
                "print(f\"\\nâœ“ Dataset downloaded to: {DATASET_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Verify Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check dataset structure\n",
                "print(\"Dataset structure:\")\n",
                "print(\"=\"*60)\n",
                "!ls -la {DATASET_PATH}\n",
                "\n",
                "print(\"\\nDataset subdirectories:\")\n",
                "for item in os.listdir(DATASET_PATH):\n",
                "    item_path = os.path.join(DATASET_PATH, item)\n",
                "    if os.path.isdir(item_path):\n",
                "        print(f\"  ðŸ“ {item}/\")\n",
                "        for subitem in os.listdir(item_path)[:5]:  # Show first 5 items\n",
                "            print(f\"      - {subitem}\")\n",
                "    else:\n",
                "        print(f\"  ðŸ“„ {item}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read dataset configuration\n",
                "yaml_path = os.path.join(DATASET_PATH, 'data.yaml')\n",
                "\n",
                "with open(yaml_path, 'r') as f:\n",
                "    config = yaml.safe_load(f)\n",
                "\n",
                "print(\"Dataset Configuration:\")\n",
                "print(\"=\"*60)\n",
                "print(yaml.dump(config, default_flow_style=False, sort_keys=False))\n",
                "\n",
                "# Extract info\n",
                "num_classes = config.get('nc', len(config.get('names', [])))\n",
                "class_names = config.get('names', [])\n",
                "\n",
                "print(f\"\\nNumber of classes: {num_classes}\")\n",
                "print(f\"Class names: {class_names}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count images in each split\n",
                "def count_images(path):\n",
                "    if not os.path.exists(path):\n",
                "        return 0\n",
                "    return len([f for f in os.listdir(path) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
                "\n",
                "train_path = os.path.join(DATASET_PATH, config.get('train', 'train/images'))\n",
                "val_path = os.path.join(DATASET_PATH, config.get('val', 'valid/images'))\n",
                "test_path = os.path.join(DATASET_PATH, config.get('test', 'test/images'))\n",
                "\n",
                "train_count = count_images(train_path)\n",
                "val_count = count_images(val_path)\n",
                "test_count = count_images(test_path)\n",
                "\n",
                "print(\"Dataset Statistics:\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Train images: {train_count:,}\")\n",
                "print(f\"Validation images: {val_count:,}\")\n",
                "print(f\"Test images: {test_count:,}\")\n",
                "print(f\"Total images: {train_count + val_count + test_count:,}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display sample images\n",
                "import random\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image as PILImage\n",
                "\n",
                "# Get random sample images\n",
                "sample_images = [f for f in os.listdir(train_path) if f.endswith(('.jpg', '.jpeg', '.png'))][:6]\n",
                "\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "fig.suptitle('Sample Training Images', fontsize=16, fontweight='bold')\n",
                "\n",
                "for idx, img_name in enumerate(sample_images):\n",
                "    img_path = os.path.join(train_path, img_name)\n",
                "    img = PILImage.open(img_path)\n",
                "    \n",
                "    ax = axes[idx // 3, idx % 3]\n",
                "    ax.imshow(img)\n",
                "    ax.set_title(img_name, fontsize=10)\n",
                "    ax.axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"Image size example: {img.size}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training hyperparameters\n",
                "EPOCHS = 100  # Recommended: 100-300 for best results\n",
                "IMG_SIZE = 640  # Standard YOLO size (can use 1280 for better accuracy)\n",
                "BATCH_SIZE = 16  # Adjust based on GPU memory (P100: 16-32, T4: 8-16)\n",
                "PATIENCE = 30  # Early stopping patience\n",
                "PROJECT_NAME = 'yolov8n_training'\n",
                "EXPERIMENT_NAME = 'roboflow_v5_j3ysc'\n",
                "\n",
                "# Advanced settings\n",
                "OPTIMIZER = 'AdamW'  # Options: 'SGD', 'Adam', 'AdamW'\n",
                "LEARNING_RATE = 0.01  # Initial learning rate\n",
                "WEIGHT_DECAY = 0.0005\n",
                "\n",
                "print(\"Training Configuration:\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Model: YOLOv8n\")\n",
                "print(f\"Epochs: {EPOCHS}\")\n",
                "print(f\"Image Size: {IMG_SIZE}\")\n",
                "print(f\"Batch Size: {BATCH_SIZE}\")\n",
                "print(f\"Patience: {PATIENCE}\")\n",
                "print(f\"Optimizer: {OPTIMIZER}\")\n",
                "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
                "print(f\"Weight Decay: {WEIGHT_DECAY}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Initialize Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load YOLOv8n with pretrained COCO weights\n",
                "model = YOLO('yolov8n.pt')\n",
                "\n",
                "print(\"âœ“ YOLOv8n model loaded with pretrained weights\")\n",
                "print(\"\\nModel Summary:\")\n",
                "model.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Train the Model\n",
                "\n",
                "This will take approximately 2-4 hours depending on dataset size and epochs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start training\n",
                "print(\"Starting training...\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "results = model.train(\n",
                "    # Dataset\n",
                "    data=yaml_path,\n",
                "    \n",
                "    # Training parameters\n",
                "    epochs=EPOCHS,\n",
                "    imgsz=IMG_SIZE,\n",
                "    batch=BATCH_SIZE,\n",
                "    patience=PATIENCE,\n",
                "    \n",
                "    # Output\n",
                "    project=PROJECT_NAME,\n",
                "    name=EXPERIMENT_NAME,\n",
                "    exist_ok=False,\n",
                "    \n",
                "    # Device\n",
                "    device=0,  # GPU 0\n",
                "    \n",
                "    # Optimizer\n",
                "    optimizer=OPTIMIZER,\n",
                "    lr0=LEARNING_RATE,\n",
                "    lrf=0.01,  # Final learning rate (lr0 * lrf)\n",
                "    momentum=0.937,\n",
                "    weight_decay=WEIGHT_DECAY,\n",
                "    \n",
                "    # Augmentation\n",
                "    hsv_h=0.015,  # HSV-Hue augmentation\n",
                "    hsv_s=0.7,  # HSV-Saturation augmentation\n",
                "    hsv_v=0.4,  # HSV-Value augmentation\n",
                "    degrees=0.0,  # Rotation (+/- deg)\n",
                "    translate=0.1,  # Translation (+/- fraction)\n",
                "    scale=0.5,  # Scaling (+/- gain)\n",
                "    shear=0.0,  # Shear (+/- deg)\n",
                "    perspective=0.0,  # Perspective (+/- fraction)\n",
                "    flipud=0.0,  # Flip up-down probability\n",
                "    fliplr=0.5,  # Flip left-right probability\n",
                "    mosaic=1.0,  # Mosaic augmentation probability\n",
                "    mixup=0.0,  # MixUp augmentation probability\n",
                "    copy_paste=0.0,  # Copy-paste augmentation probability\n",
                "    \n",
                "    # Validation\n",
                "    val=True,\n",
                "    \n",
                "    # Saving\n",
                "    save=True,\n",
                "    save_period=-1,  # Save checkpoint every x epochs (-1 = only save last and best)\n",
                "    \n",
                "    # Performance\n",
                "    cache=False,  # Set True if enough RAM (faster training)\n",
                "    workers=8,\n",
                "    \n",
                "    # Other\n",
                "    pretrained=True,\n",
                "    verbose=True,\n",
                "    seed=0,\n",
                "    deterministic=True,\n",
                "    plots=True,\n",
                "    \n",
                "    # Advanced\n",
                "    amp=True,  # Automatic Mixed Precision\n",
                "    fraction=1.0,  # Dataset fraction to train on\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"âœ“ Training completed!\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Evaluate Model Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "best_model_path = f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/best.pt'\n",
                "best_model = YOLO(best_model_path)\n",
                "\n",
                "print(f\"âœ“ Loaded best model from: {best_model_path}\")\n",
                "print(f\"Model size: {os.path.getsize(best_model_path) / (1024 * 1024):.2f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate on validation set\n",
                "print(\"Running validation...\")\n",
                "metrics = best_model.val(\n",
                "    data=yaml_path,\n",
                "    imgsz=IMG_SIZE,\n",
                "    batch=BATCH_SIZE,\n",
                "    conf=0.25,  # Confidence threshold\n",
                "    iou=0.6,  # IoU threshold for NMS\n",
                "    device=0,\n",
                "    plots=True,\n",
                "    save_json=True,\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"VALIDATION METRICS\")\n",
                "print(\"=\"*60)\n",
                "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
                "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
                "print(f\"mAP75: {metrics.box.map75:.4f}\")\n",
                "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
                "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Per-class metrics\n",
                "print(\"\\nPER-CLASS METRICS (AP50):\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "for i in range(num_classes):\n",
                "    class_name = class_names[i] if isinstance(class_names, list) else class_names.get(i, f'class_{i}')\n",
                "    ap50 = metrics.box.ap50[i]\n",
                "    ap = metrics.box.ap[i]\n",
                "    \n",
                "    print(f\"{class_name:20s} | AP50: {ap50:.4f} | AP50-95: {ap:.4f}\")\n",
                "\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Visualize Training Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training curves\n",
                "results_path = f'{PROJECT_NAME}/{EXPERIMENT_NAME}'\n",
                "\n",
                "results_img = f'{results_path}/results.png'\n",
                "if os.path.exists(results_img):\n",
                "    print(\"Training Curves:\")\n",
                "    display(Image(filename=results_img, width=1000))\n",
                "else:\n",
                "    print(\"Results plot not found\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix\n",
                "confusion_matrix = f'{results_path}/confusion_matrix.png'\n",
                "if os.path.exists(confusion_matrix):\n",
                "    print(\"Confusion Matrix:\")\n",
                "    display(Image(filename=confusion_matrix, width=800))\n",
                "else:\n",
                "    print(\"Confusion matrix not found\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PR Curve\n",
                "pr_curve = f'{results_path}/PR_curve.png'\n",
                "if os.path.exists(pr_curve):\n",
                "    print(\"Precision-Recall Curve:\")\n",
                "    display(Image(filename=pr_curve, width=800))\n",
                "\n",
                "# F1 Curve\n",
                "f1_curve = f'{results_path}/F1_curve.png'\n",
                "if os.path.exists(f1_curve):\n",
                "    print(\"\\nF1 Score Curve:\")\n",
                "    display(Image(filename=f1_curve, width=800))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validation predictions\n",
                "val_batches = sorted(glob.glob(f'{results_path}/val_batch*.jpg'))\n",
                "\n",
                "if val_batches:\n",
                "    print(f\"Validation Predictions (showing {min(3, len(val_batches))} batches):\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    for batch_img in val_batches[:3]:\n",
                "        print(f\"\\n{os.path.basename(batch_img)}\")\n",
                "        display(Image(filename=batch_img, width=900))\n",
                "else:\n",
                "    print(\"No validation batch images found\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Test on Sample Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get test images\n",
                "if test_count > 0:\n",
                "    test_source = test_path\n",
                "    print(f\"Using test set: {test_count} images\")\n",
                "else:\n",
                "    test_source = val_path\n",
                "    print(f\"Test set not available, using validation set: {val_count} images\")\n",
                "\n",
                "# Get sample images\n",
                "test_images = [os.path.join(test_source, f) for f in os.listdir(test_source) \n",
                "               if f.endswith(('.jpg', '.jpeg', '.png'))][:10]\n",
                "\n",
                "print(f\"\\nRunning inference on {len(test_images)} sample images...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run predictions\n",
                "predictions = best_model.predict(\n",
                "    source=test_images,\n",
                "    imgsz=IMG_SIZE,\n",
                "    conf=0.25,  # Confidence threshold\n",
                "    iou=0.45,  # IoU threshold for NMS\n",
                "    device=0,\n",
                "    save=True,\n",
                "    save_txt=True,\n",
                "    save_conf=True,\n",
                "    project=f'{PROJECT_NAME}/predictions',\n",
                "    name='test_samples',\n",
                "    exist_ok=True,\n",
                ")\n",
                "\n",
                "print(f\"âœ“ Predictions saved to: {PROJECT_NAME}/predictions/test_samples/\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display predictions\n",
                "pred_images = sorted(glob.glob(f'{PROJECT_NAME}/predictions/test_samples/*.jpg'))\n",
                "\n",
                "print(f\"\\nSample Predictions ({len(pred_images)} images):\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "for pred_img in pred_images[:6]:  # Show first 6\n",
                "    print(f\"\\n{os.path.basename(pred_img)}\")\n",
                "    display(Image(filename=pred_img, width=700))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze predictions\n",
                "print(\"\\nPrediction Analysis:\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "total_detections = 0\n",
                "class_counts = {name: 0 for name in class_names}\n",
                "\n",
                "for result in predictions:\n",
                "    boxes = result.boxes\n",
                "    total_detections += len(boxes)\n",
                "    \n",
                "    for box in boxes:\n",
                "        cls_id = int(box.cls[0])\n",
                "        cls_name = class_names[cls_id] if isinstance(class_names, list) else class_names.get(cls_id, f'class_{cls_id}')\n",
                "        class_counts[cls_name] = class_counts.get(cls_name, 0) + 1\n",
                "\n",
                "print(f\"Total detections: {total_detections}\")\n",
                "print(f\"Average detections per image: {total_detections / len(predictions):.2f}\")\n",
                "print(\"\\nDetections per class:\")\n",
                "for cls_name, count in class_counts.items():\n",
                "    print(f\"  {cls_name}: {count}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Export Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to ONNX format (recommended for deployment)\n",
                "print(\"Exporting model to ONNX format...\")\n",
                "onnx_path = best_model.export(\n",
                "    format='onnx',\n",
                "    imgsz=IMG_SIZE,\n",
                "    dynamic=False,  # Set True for dynamic input sizes\n",
                "    simplify=True,  # Simplify ONNX model\n",
                ")\n",
                "\n",
                "print(f\"âœ“ ONNX model exported to: {onnx_path}\")\n",
                "print(f\"  Size: {os.path.getsize(onnx_path) / (1024 * 1024):.2f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optional: Export to other formats\n",
                "# Uncomment the format you need\n",
                "\n",
                "# TorchScript\n",
                "# torchscript_path = best_model.export(format='torchscript')\n",
                "# print(f\"TorchScript: {torchscript_path}\")\n",
                "\n",
                "# TensorFlow Lite\n",
                "# tflite_path = best_model.export(format='tflite')\n",
                "# print(f\"TFLite: {tflite_path}\")\n",
                "\n",
                "# TensorFlow SavedModel\n",
                "# saved_model_path = best_model.export(format='saved_model')\n",
                "# print(f\"TensorFlow SavedModel: {saved_model_path}\")\n",
                "\n",
                "# CoreML (for iOS)\n",
                "# coreml_path = best_model.export(format='coreml')\n",
                "# print(f\"CoreML: {coreml_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Model Information & Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model architecture info\n",
                "print(\"Model Architecture Summary:\")\n",
                "print(\"=\"*60)\n",
                "best_model.info(verbose=True, detailed=True)\n",
                "\n",
                "# Count parameters\n",
                "total_params = sum(p.numel() for p in best_model.model.parameters())\n",
                "trainable_params = sum(p.numel() for p in best_model.model.parameters() if p.requires_grad)\n",
                "\n",
                "print(f\"\\nModel Statistics:\")\n",
                "print(f\"  Total parameters: {total_params:,}\")\n",
                "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
                "print(f\"  Model size (PT): {os.path.getsize(best_model_path) / (1024 * 1024):.2f} MB\")\n",
                "print(f\"  Model size (ONNX): {os.path.getsize(onnx_path) / (1024 * 1024):.2f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comprehensive training summary\n",
                "summary_path = f'{PROJECT_NAME}/{EXPERIMENT_NAME}/TRAINING_SUMMARY.txt'\n",
                "\n",
                "with open(summary_path, 'w', encoding='utf-8') as f:\n",
                "    f.write(\"=\"*80 + \"\\n\")\n",
                "    f.write(\"YOLOv8n TRAINING SUMMARY\\n\")\n",
                "    f.write(\"=\"*80 + \"\\n\\n\")\n",
                "    \n",
                "    f.write(\"DATASET INFORMATION\\n\")\n",
                "    f.write(\"-\" * 80 + \"\\n\")\n",
                "    f.write(f\"Source: Roboflow Universe\\n\")\n",
                "    f.write(f\"Workspace: {WORKSPACE}\\n\")\n",
                "    f.write(f\"Project: {PROJECT}\\n\")\n",
                "    f.write(f\"Version: {VERSION}\\n\")\n",
                "    f.write(f\"URL: https://universe.roboflow.com/{WORKSPACE}/{PROJECT}/dataset/{VERSION}\\n\")\n",
                "    f.write(f\"\\nDataset Statistics:\\n\")\n",
                "    f.write(f\"  Train images: {train_count:,}\\n\")\n",
                "    f.write(f\"  Validation images: {val_count:,}\\n\")\n",
                "    f.write(f\"  Test images: {test_count:,}\\n\")\n",
                "    f.write(f\"  Total images: {train_count + val_count + test_count:,}\\n\")\n",
                "    f.write(f\"  Number of classes: {num_classes}\\n\")\n",
                "    f.write(f\"  Class names: {class_names}\\n\")\n",
                "    \n",
                "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
                "    f.write(\"TRAINING CONFIGURATION\\n\")\n",
                "    f.write(\"-\" * 80 + \"\\n\")\n",
                "    f.write(f\"Model: YOLOv8n\\n\")\n",
                "    f.write(f\"Epochs: {EPOCHS}\\n\")\n",
                "    f.write(f\"Image Size: {IMG_SIZE}\\n\")\n",
                "    f.write(f\"Batch Size: {BATCH_SIZE}\\n\")\n",
                "    f.write(f\"Patience: {PATIENCE}\\n\")\n",
                "    f.write(f\"Optimizer: {OPTIMIZER}\\n\")\n",
                "    f.write(f\"Learning Rate: {LEARNING_RATE}\\n\")\n",
                "    f.write(f\"Weight Decay: {WEIGHT_DECAY}\\n\")\n",
                "    f.write(f\"Device: {torch.cuda.get_device_name(0)}\\n\")\n",
                "    \n",
                "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
                "    f.write(\"VALIDATION METRICS\\n\")\n",
                "    f.write(\"-\" * 80 + \"\\n\")\n",
                "    f.write(f\"mAP50-95: {metrics.box.map:.4f}\\n\")\n",
                "    f.write(f\"mAP50: {metrics.box.map50:.4f}\\n\")\n",
                "    f.write(f\"mAP75: {metrics.box.map75:.4f}\\n\")\n",
                "    f.write(f\"Precision: {metrics.box.mp:.4f}\\n\")\n",
                "    f.write(f\"Recall: {metrics.box.mr:.4f}\\n\")\n",
                "    \n",
                "    f.write(\"\\nPer-Class Metrics (AP50):\\n\")\n",
                "    for i in range(num_classes):\n",
                "        cls_name = class_names[i] if isinstance(class_names, list) else class_names.get(i, f'class_{i}')\n",
                "        f.write(f\"  {cls_name:20s}: {metrics.box.ap50[i]:.4f}\\n\")\n",
                "    \n",
                "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
                "    f.write(\"MODEL INFORMATION\\n\")\n",
                "    f.write(\"-\" * 80 + \"\\n\")\n",
                "    f.write(f\"Total parameters: {total_params:,}\\n\")\n",
                "    f.write(f\"Trainable parameters: {trainable_params:,}\\n\")\n",
                "    f.write(f\"Model size (PyTorch): {os.path.getsize(best_model_path) / (1024 * 1024):.2f} MB\\n\")\n",
                "    f.write(f\"Model size (ONNX): {os.path.getsize(onnx_path) / (1024 * 1024):.2f} MB\\n\")\n",
                "    \n",
                "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
                "    f.write(\"OUTPUT FILES\\n\")\n",
                "    f.write(\"-\" * 80 + \"\\n\")\n",
                "    f.write(f\"Best model: {best_model_path}\\n\")\n",
                "    f.write(f\"Last model: {PROJECT_NAME}/{EXPERIMENT_NAME}/weights/last.pt\\n\")\n",
                "    f.write(f\"ONNX model: {onnx_path}\\n\")\n",
                "    f.write(f\"Results: {results_path}/results.csv\\n\")\n",
                "    f.write(f\"Plots: {results_path}/*.png\\n\")\n",
                "    \n",
                "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
                "\n",
                "print(f\"âœ“ Training summary saved to: {summary_path}\")\n",
                "\n",
                "# Display summary\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "with open(summary_path, 'r', encoding='utf-8') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Package Results for Download"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List all important files\n",
                "print(\"Important Files:\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "important_files = [\n",
                "    (f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/best.pt', 'Best model weights'),\n",
                "    (f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/last.pt', 'Last epoch weights'),\n",
                "    (onnx_path, 'ONNX model'),\n",
                "    (f'{PROJECT_NAME}/{EXPERIMENT_NAME}/results.csv', 'Training results CSV'),\n",
                "    (f'{PROJECT_NAME}/{EXPERIMENT_NAME}/results.png', 'Training curves'),\n",
                "    (f'{PROJECT_NAME}/{EXPERIMENT_NAME}/confusion_matrix.png', 'Confusion matrix'),\n",
                "    (f'{PROJECT_NAME}/{EXPERIMENT_NAME}/PR_curve.png', 'PR curve'),\n",
                "    (f'{PROJECT_NAME}/{EXPERIMENT_NAME}/F1_curve.png', 'F1 curve'),\n",
                "    (summary_path, 'Training summary'),\n",
                "]\n",
                "\n",
                "total_size = 0\n",
                "for file_path, description in important_files:\n",
                "    if os.path.exists(file_path):\n",
                "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
                "        total_size += size_mb\n",
                "        print(f\"âœ“ {description:30s} | {size_mb:8.2f} MB | {file_path}\")\n",
                "    else:\n",
                "        print(f\"âœ— {description:30s} | NOT FOUND | {file_path}\")\n",
                "\n",
                "print(\"=\"*80)\n",
                "print(f\"Total size: {total_size:.2f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create ZIP archive with all results\n",
                "import zipfile\n",
                "from datetime import datetime\n",
                "\n",
                "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
                "zip_filename = f'yolov8n_roboflow_results_{timestamp}.zip'\n",
                "\n",
                "print(f\"Creating archive: {zip_filename}\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
                "    # Add weights\n",
                "    print(\"Adding weights...\")\n",
                "    zipf.write(f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/best.pt', 'weights/best.pt')\n",
                "    zipf.write(f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/last.pt', 'weights/last.pt')\n",
                "    \n",
                "    # Add ONNX model\n",
                "    print(\"Adding ONNX model...\")\n",
                "    zipf.write(onnx_path, f'weights/{os.path.basename(onnx_path)}')\n",
                "    \n",
                "    # Add plots\n",
                "    print(\"Adding plots...\")\n",
                "    for plot_file in glob.glob(f'{PROJECT_NAME}/{EXPERIMENT_NAME}/*.png'):\n",
                "        zipf.write(plot_file, f'plots/{os.path.basename(plot_file)}')\n",
                "    \n",
                "    # Add CSV results\n",
                "    print(\"Adding results...\")\n",
                "    csv_file = f'{PROJECT_NAME}/{EXPERIMENT_NAME}/results.csv'\n",
                "    if os.path.exists(csv_file):\n",
                "        zipf.write(csv_file, 'results.csv')\n",
                "    \n",
                "    # Add summary\n",
                "    print(\"Adding summary...\")\n",
                "    zipf.write(summary_path, 'TRAINING_SUMMARY.txt')\n",
                "    \n",
                "    # Add sample predictions\n",
                "    print(\"Adding sample predictions...\")\n",
                "    for pred_img in pred_images[:5]:\n",
                "        zipf.write(pred_img, f'predictions/{os.path.basename(pred_img)}')\n",
                "    \n",
                "    # Add dataset config\n",
                "    print(\"Adding dataset config...\")\n",
                "    zipf.write(yaml_path, 'data.yaml')\n",
                "\n",
                "zip_size = os.path.getsize(zip_filename) / (1024 * 1024)\n",
                "print(\"=\"*80)\n",
                "print(f\"âœ“ Archive created successfully!\")\n",
                "print(f\"  Filename: {zip_filename}\")\n",
                "print(f\"  Size: {zip_size:.2f} MB\")\n",
                "print(f\"\\nðŸ“¥ Download this file from Kaggle's output panel (right sidebar)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Quick Inference Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a quick inference function for testing\n",
                "def predict_image(image_path, conf=0.25, save=True):\n",
                "    \"\"\"\n",
                "    Quick inference on a single image\n",
                "    \n",
                "    Args:\n",
                "        image_path: Path to image file\n",
                "        conf: Confidence threshold (0-1)\n",
                "        save: Whether to save the result\n",
                "    \"\"\"\n",
                "    results = best_model.predict(\n",
                "        source=image_path,\n",
                "        imgsz=IMG_SIZE,\n",
                "        conf=conf,\n",
                "        save=save,\n",
                "        device=0,\n",
                "    )\n",
                "    \n",
                "    # Display results\n",
                "    for result in results:\n",
                "        boxes = result.boxes\n",
                "        print(f\"\\nDetections: {len(boxes)}\")\n",
                "        \n",
                "        for box in boxes:\n",
                "            cls_id = int(box.cls[0])\n",
                "            conf_score = float(box.conf[0])\n",
                "            cls_name = class_names[cls_id] if isinstance(class_names, list) else class_names.get(cls_id, f'class_{cls_id}')\n",
                "            \n",
                "            print(f\"  {cls_name}: {conf_score:.2f}\")\n",
                "        \n",
                "        # Show image\n",
                "        result.show()\n",
                "    \n",
                "    return results\n",
                "\n",
                "print(\"âœ“ Quick inference function created!\")\n",
                "print(\"\\nUsage: predict_image('path/to/image.jpg', conf=0.25)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test the inference function\n",
                "if test_images:\n",
                "    print(\"Testing inference function on a sample image...\")\n",
                "    sample_result = predict_image(test_images[0], conf=0.25)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“Š Training Complete!\n",
                "\n",
                "### What's Next?\n",
                "\n",
                "1. **Download Results**: Get the ZIP file from Kaggle's output panel\n",
                "2. **Test Locally**: Use the exported ONNX or PyTorch model\n",
                "3. **Deploy**: Integrate into your application\n",
                "4. **Fine-tune**: Adjust hyperparameters if needed\n",
                "\n",
                "### Tips for Better Results\n",
                "\n",
                "- **More epochs**: Try 150-300 epochs\n",
                "- **Larger model**: Use YOLOv8s or YOLOv8m for better accuracy\n",
                "- **Higher resolution**: Use `imgsz=1280` (slower but more accurate)\n",
                "- **Data augmentation**: Adjust augmentation parameters\n",
                "- **Learning rate**: Experiment with different values\n",
                "\n",
                "### Common Issues\n",
                "\n",
                "- **Out of Memory**: Reduce batch size or image size\n",
                "- **Poor mAP**: Check dataset quality, increase epochs\n",
                "- **Overfitting**: Increase augmentation, add more data\n",
                "- **Slow training**: Enable caching (`cache=True`)\n",
                "\n",
                "### Resources\n",
                "\n",
                "- [Ultralytics Docs](https://docs.ultralytics.com/)\n",
                "- [YOLOv8 Training Guide](https://docs.ultralytics.com/modes/train/)\n",
                "- [Roboflow Universe](https://universe.roboflow.com/)\n",
                "- [Model Export Guide](https://docs.ultralytics.com/modes/export/)\n",
                "\n",
                "---\n",
                "\n",
                "**Happy Training! ðŸš€**"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "gpuClass": "standard",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
