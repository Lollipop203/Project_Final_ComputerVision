{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# YOLOv8n Traffic Light Detection Training on Kaggle\n",
                "\n",
                "This notebook trains a YOLOv8n model for traffic light detection using Kaggle's free GPU.\n",
                "\n",
                "## Prerequisites\n",
                "- Upload your dataset to Kaggle Datasets\n",
                "- Enable GPU accelerator (Settings → Accelerator → GPU P100)\n",
                "- Make sure your dataset follows YOLO format with `dataset.yaml`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install -q ultralytics\n",
                "!pip install -q roboflow  # Optional: if using Roboflow datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import os\n",
                "import yaml\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "from ultralytics import YOLO\n",
                "import torch\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"CUDA version: {torch.version.cuda}\")\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset Setup\n",
                "\n",
                "### Option A: Using Kaggle Dataset\n",
                "If you uploaded your dataset to Kaggle, add it as a data source in the notebook settings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set dataset path - Update this to match your Kaggle dataset path\n",
                "# Example: /kaggle/input/your-dataset-name/\n",
                "DATASET_PATH = '/kaggle/input/traffic-light-dataset/'  # Change this!\n",
                "\n",
                "# Verify dataset structure\n",
                "print(\"Dataset contents:\")\n",
                "!ls -la {DATASET_PATH}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Option B: Download from Roboflow or URL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment if downloading from Roboflow\n",
                "# from roboflow import Roboflow\n",
                "# rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
                "# project = rf.workspace(\"YOUR_WORKSPACE\").project(\"YOUR_PROJECT\")\n",
                "# dataset = project.version(1).download(\"yolov8\")\n",
                "# DATASET_PATH = dataset.location"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Verify Dataset Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find and read dataset.yaml\n",
                "yaml_path = os.path.join(DATASET_PATH, 'dataset.yaml')\n",
                "# Alternative common names\n",
                "if not os.path.exists(yaml_path):\n",
                "    yaml_path = os.path.join(DATASET_PATH, 'data.yaml')\n",
                "\n",
                "print(f\"Using config: {yaml_path}\")\n",
                "\n",
                "# Read and display dataset config\n",
                "with open(yaml_path, 'r') as f:\n",
                "    dataset_config = yaml.safe_load(f)\n",
                "    print(\"\\nDataset Configuration:\")\n",
                "    print(yaml.dump(dataset_config, default_flow_style=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Update paths in dataset.yaml if needed\n",
                "# This is important if the yaml has relative paths\n",
                "with open(yaml_path, 'r') as f:\n",
                "    config = yaml.safe_load(f)\n",
                "\n",
                "# Update path to absolute path\n",
                "config['path'] = DATASET_PATH\n",
                "\n",
                "# Save updated config\n",
                "updated_yaml_path = '/kaggle/working/dataset.yaml'\n",
                "with open(updated_yaml_path, 'w') as f:\n",
                "    yaml.dump(config, f, default_flow_style=False)\n",
                "\n",
                "print(f\"Updated config saved to: {updated_yaml_path}\")\n",
                "yaml_path = updated_yaml_path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify dataset structure\n",
                "train_images = os.path.join(DATASET_PATH, config.get('train', 'train/images'))\n",
                "val_images = os.path.join(DATASET_PATH, config.get('val', 'val/images'))\n",
                "\n",
                "print(f\"\\nTrain images path: {train_images}\")\n",
                "print(f\"Exists: {os.path.exists(train_images)}\")\n",
                "if os.path.exists(train_images):\n",
                "    train_count = len([f for f in os.listdir(train_images) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
                "    print(f\"Train images count: {train_count}\")\n",
                "\n",
                "print(f\"\\nVal images path: {val_images}\")\n",
                "print(f\"Exists: {os.path.exists(val_images)}\")\n",
                "if os.path.exists(val_images):\n",
                "    val_count = len([f for f in os.listdir(val_images) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
                "    print(f\"Val images count: {val_count}\")\n",
                "\n",
                "print(f\"\\nNumber of classes: {config.get('nc', 'Not specified')}\")\n",
                "print(f\"Class names: {config.get('names', 'Not specified')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Initialize YOLOv8n Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load YOLOv8n model\n",
                "# Use pretrained COCO weights for transfer learning\n",
                "model = YOLO('yolov8n.pt')\n",
                "\n",
                "# Or start from scratch (not recommended)\n",
                "# model = YOLO('yolov8n.yaml')\n",
                "\n",
                "print(\"Model loaded successfully!\")\n",
                "print(f\"Model type: {type(model)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training hyperparameters\n",
                "EPOCHS = 100  # Adjust based on your needs\n",
                "IMG_SIZE = 640  # Standard YOLO input size\n",
                "BATCH_SIZE = 16  # Adjust based on GPU memory (P100 can handle 16-32)\n",
                "PATIENCE = 20  # Early stopping patience\n",
                "PROJECT_NAME = 'traffic_light_detection'\n",
                "EXPERIMENT_NAME = 'yolov8n_run1'\n",
                "\n",
                "print(f\"Training Configuration:\")\n",
                "print(f\"  Epochs: {EPOCHS}\")\n",
                "print(f\"  Image Size: {IMG_SIZE}\")\n",
                "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
                "print(f\"  Patience: {PATIENCE}\")\n",
                "print(f\"  Project: {PROJECT_NAME}\")\n",
                "print(f\"  Experiment: {EXPERIMENT_NAME}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Train the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "results = model.train(\n",
                "    data=yaml_path,\n",
                "    epochs=EPOCHS,\n",
                "    imgsz=IMG_SIZE,\n",
                "    batch=BATCH_SIZE,\n",
                "    patience=PATIENCE,\n",
                "    project=PROJECT_NAME,\n",
                "    name=EXPERIMENT_NAME,\n",
                "    device=0,  # Use GPU 0\n",
                "    \n",
                "    # Optimization settings\n",
                "    optimizer='AdamW',  # or 'SGD', 'Adam'\n",
                "    lr0=0.01,  # Initial learning rate\n",
                "    lrf=0.01,  # Final learning rate (lr0 * lrf)\n",
                "    momentum=0.937,  # SGD momentum/Adam beta1\n",
                "    weight_decay=0.0005,  # Optimizer weight decay\n",
                "    \n",
                "    # Augmentation settings\n",
                "    hsv_h=0.015,  # HSV-Hue augmentation\n",
                "    hsv_s=0.7,  # HSV-Saturation augmentation\n",
                "    hsv_v=0.4,  # HSV-Value augmentation\n",
                "    degrees=0.0,  # Rotation (+/- deg)\n",
                "    translate=0.1,  # Translation (+/- fraction)\n",
                "    scale=0.5,  # Scaling (+/- gain)\n",
                "    shear=0.0,  # Shear (+/- deg)\n",
                "    perspective=0.0,  # Perspective (+/- fraction)\n",
                "    flipud=0.0,  # Flip up-down (probability)\n",
                "    fliplr=0.5,  # Flip left-right (probability)\n",
                "    mosaic=1.0,  # Mosaic augmentation (probability)\n",
                "    mixup=0.0,  # MixUp augmentation (probability)\n",
                "    \n",
                "    # Other settings\n",
                "    save=True,  # Save checkpoints\n",
                "    save_period=-1,  # Save checkpoint every x epochs (-1 = disabled)\n",
                "    cache=False,  # Cache images for faster training (use True if enough RAM)\n",
                "    workers=8,  # Number of worker threads\n",
                "    pretrained=True,  # Use pretrained weights\n",
                "    verbose=True,  # Verbose output\n",
                "    seed=0,  # Random seed for reproducibility\n",
                "    deterministic=True,  # Deterministic mode\n",
                "    \n",
                "    # Validation settings\n",
                "    val=True,  # Validate during training\n",
                "    plots=True,  # Save plots\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"Training completed!\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Evaluate the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the best model\n",
                "best_model_path = f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/best.pt'\n",
                "best_model = YOLO(best_model_path)\n",
                "\n",
                "print(f\"Loaded best model from: {best_model_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate on validation set\n",
                "metrics = best_model.val(\n",
                "    data=yaml_path,\n",
                "    imgsz=IMG_SIZE,\n",
                "    batch=BATCH_SIZE,\n",
                "    conf=0.25,  # Confidence threshold\n",
                "    iou=0.6,  # IoU threshold for NMS\n",
                "    device=0,\n",
                "    plots=True,\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"Validation Metrics:\")\n",
                "print(\"=\"*50)\n",
                "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
                "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
                "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
                "print(f\"Recall: {metrics.box.mr:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display per-class metrics\n",
                "print(\"\\nPer-class metrics:\")\n",
                "print(\"-\" * 50)\n",
                "for i, class_name in enumerate(config['names']):\n",
                "    if isinstance(config['names'], dict):\n",
                "        class_name = config['names'][i]\n",
                "    print(f\"{class_name}:\")\n",
                "    print(f\"  AP50: {metrics.box.ap50[i]:.4f}\")\n",
                "    print(f\"  AP: {metrics.box.ap[i]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Visualize Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display training plots\n",
                "from IPython.display import Image, display\n",
                "import glob\n",
                "\n",
                "results_path = f'{PROJECT_NAME}/{EXPERIMENT_NAME}'\n",
                "\n",
                "# Show confusion matrix\n",
                "confusion_matrix_path = f'{results_path}/confusion_matrix.png'\n",
                "if os.path.exists(confusion_matrix_path):\n",
                "    print(\"Confusion Matrix:\")\n",
                "    display(Image(filename=confusion_matrix_path))\n",
                "\n",
                "# Show results\n",
                "results_img_path = f'{results_path}/results.png'\n",
                "if os.path.exists(results_img_path):\n",
                "    print(\"\\nTraining Results:\")\n",
                "    display(Image(filename=results_img_path))\n",
                "\n",
                "# Show PR curve\n",
                "pr_curve_path = f'{results_path}/PR_curve.png'\n",
                "if os.path.exists(pr_curve_path):\n",
                "    print(\"\\nPrecision-Recall Curve:\")\n",
                "    display(Image(filename=pr_curve_path))\n",
                "\n",
                "# Show F1 curve\n",
                "f1_curve_path = f'{results_path}/F1_curve.png'\n",
                "if os.path.exists(f1_curve_path):\n",
                "    print(\"\\nF1 Curve:\")\n",
                "    display(Image(filename=f1_curve_path))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show validation batch predictions\n",
                "val_batches = glob.glob(f'{results_path}/val_batch*.jpg')\n",
                "if val_batches:\n",
                "    print(\"\\nValidation Batch Predictions:\")\n",
                "    for batch_img in val_batches[:3]:  # Show first 3 batches\n",
                "        print(f\"\\n{os.path.basename(batch_img)}:\")\n",
                "        display(Image(filename=batch_img, width=800))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Test on Sample Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get some test images\n",
                "test_images_path = os.path.join(DATASET_PATH, config.get('test', 'test/images'))\n",
                "if not os.path.exists(test_images_path):\n",
                "    test_images_path = val_images  # Use val images if test not available\n",
                "\n",
                "test_images = [os.path.join(test_images_path, f) for f in os.listdir(test_images_path) \n",
                "               if f.endswith(('.jpg', '.jpeg', '.png'))][:5]  # Get first 5 images\n",
                "\n",
                "print(f\"Testing on {len(test_images)} sample images...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run inference\n",
                "predictions = best_model.predict(\n",
                "    source=test_images,\n",
                "    imgsz=IMG_SIZE,\n",
                "    conf=0.25,\n",
                "    iou=0.45,\n",
                "    device=0,\n",
                "    save=True,\n",
                "    project=f'{PROJECT_NAME}/predictions',\n",
                "    name='test_samples',\n",
                ")\n",
                "\n",
                "print(f\"Predictions saved to: {PROJECT_NAME}/predictions/test_samples/\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display predictions\n",
                "pred_images = glob.glob(f'{PROJECT_NAME}/predictions/test_samples/*.jpg')\n",
                "print(f\"\\nSample Predictions ({len(pred_images)} images):\")\n",
                "for pred_img in pred_images:\n",
                "    print(f\"\\n{os.path.basename(pred_img)}:\")\n",
                "    display(Image(filename=pred_img, width=600))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Export Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to different formats\n",
                "# PyTorch format (already saved)\n",
                "print(f\"PyTorch model: {best_model_path}\")\n",
                "\n",
                "# Export to ONNX (for deployment)\n",
                "onnx_path = best_model.export(format='onnx', imgsz=IMG_SIZE)\n",
                "print(f\"ONNX model exported to: {onnx_path}\")\n",
                "\n",
                "# Uncomment to export to other formats\n",
                "# torchscript_path = best_model.export(format='torchscript')\n",
                "# tflite_path = best_model.export(format='tflite')\n",
                "# edgetpu_path = best_model.export(format='edgetpu')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Save Results and Download"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a summary file\n",
                "summary_path = f'{PROJECT_NAME}/{EXPERIMENT_NAME}/training_summary.txt'\n",
                "with open(summary_path, 'w') as f:\n",
                "    f.write(\"YOLOv8n Traffic Light Detection - Training Summary\\n\")\n",
                "    f.write(\"=\"*60 + \"\\n\\n\")\n",
                "    \n",
                "    f.write(\"Training Configuration:\\n\")\n",
                "    f.write(f\"  Model: YOLOv8n\\n\")\n",
                "    f.write(f\"  Epochs: {EPOCHS}\\n\")\n",
                "    f.write(f\"  Image Size: {IMG_SIZE}\\n\")\n",
                "    f.write(f\"  Batch Size: {BATCH_SIZE}\\n\")\n",
                "    f.write(f\"  Dataset: {DATASET_PATH}\\n\")\n",
                "    f.write(f\"  Classes: {config.get('nc')}\\n\")\n",
                "    f.write(f\"  Class Names: {config.get('names')}\\n\\n\")\n",
                "    \n",
                "    f.write(\"Validation Metrics:\\n\")\n",
                "    f.write(f\"  mAP50: {metrics.box.map50:.4f}\\n\")\n",
                "    f.write(f\"  mAP50-95: {metrics.box.map:.4f}\\n\")\n",
                "    f.write(f\"  Precision: {metrics.box.mp:.4f}\\n\")\n",
                "    f.write(f\"  Recall: {metrics.box.mr:.4f}\\n\\n\")\n",
                "    \n",
                "    f.write(\"Per-class AP50:\\n\")\n",
                "    for i, class_name in enumerate(config['names']):\n",
                "        if isinstance(config['names'], dict):\n",
                "            class_name = config['names'][i]\n",
                "        f.write(f\"  {class_name}: {metrics.box.ap50[i]:.4f}\\n\")\n",
                "    \n",
                "    f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
                "    f.write(f\"Best model saved to: {best_model_path}\\n\")\n",
                "    f.write(f\"ONNX model saved to: {onnx_path}\\n\")\n",
                "\n",
                "print(f\"Training summary saved to: {summary_path}\")\n",
                "print(\"\\nTraining summary:\")\n",
                "with open(summary_path, 'r') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List all important files\n",
                "print(\"\\nImportant files to download:\")\n",
                "print(\"-\" * 60)\n",
                "important_files = [\n",
                "    f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/best.pt',\n",
                "    f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/last.pt',\n",
                "    f'{PROJECT_NAME}/{EXPERIMENT_NAME}/results.csv',\n",
                "    f'{PROJECT_NAME}/{EXPERIMENT_NAME}/results.png',\n",
                "    f'{PROJECT_NAME}/{EXPERIMENT_NAME}/confusion_matrix.png',\n",
                "    summary_path,\n",
                "]\n",
                "\n",
                "for file_path in important_files:\n",
                "    if os.path.exists(file_path):\n",
                "        size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
                "        print(f\"✓ {file_path} ({size:.2f} MB)\")\n",
                "    else:\n",
                "        print(f\"✗ {file_path} (not found)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optional: Create a zip file with all results\n",
                "import zipfile\n",
                "\n",
                "zip_filename = f'{PROJECT_NAME}_{EXPERIMENT_NAME}_results.zip'\n",
                "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
                "    # Add weights\n",
                "    zipf.write(f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/best.pt', 'weights/best.pt')\n",
                "    zipf.write(f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/last.pt', 'weights/last.pt')\n",
                "    \n",
                "    # Add results\n",
                "    for file in glob.glob(f'{PROJECT_NAME}/{EXPERIMENT_NAME}/*.png'):\n",
                "        zipf.write(file, f'results/{os.path.basename(file)}')\n",
                "    \n",
                "    # Add CSV results\n",
                "    if os.path.exists(f'{PROJECT_NAME}/{EXPERIMENT_NAME}/results.csv'):\n",
                "        zipf.write(f'{PROJECT_NAME}/{EXPERIMENT_NAME}/results.csv', 'results.csv')\n",
                "    \n",
                "    # Add summary\n",
                "    zipf.write(summary_path, 'training_summary.txt')\n",
                "\n",
                "print(f\"\\nAll results packaged in: {zip_filename}\")\n",
                "print(f\"Size: {os.path.getsize(zip_filename) / (1024 * 1024):.2f} MB\")\n",
                "print(\"\\nYou can download this file from the Kaggle output panel.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Model Information"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display model information\n",
                "print(\"Model Architecture Summary:\")\n",
                "print(\"=\"*60)\n",
                "best_model.info(verbose=True)\n",
                "\n",
                "# Count parameters\n",
                "total_params = sum(p.numel() for p in best_model.model.parameters())\n",
                "trainable_params = sum(p.numel() for p in best_model.model.parameters() if p.requires_grad)\n",
                "\n",
                "print(f\"\\nTotal parameters: {total_params:,}\")\n",
                "print(f\"Trainable parameters: {trainable_params:,}\")\n",
                "print(f\"Model size: {os.path.getsize(best_model_path) / (1024 * 1024):.2f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Notes\n",
                "\n",
                "### Tips for Better Results:\n",
                "1. **Increase epochs**: Try 150-300 epochs for better convergence\n",
                "2. **Adjust batch size**: Larger batch size (32-64) if GPU memory allows\n",
                "3. **Enable caching**: Set `cache=True` if you have enough RAM (speeds up training)\n",
                "4. **Data augmentation**: Adjust augmentation parameters based on your dataset\n",
                "5. **Learning rate**: Experiment with different learning rates (0.001 - 0.01)\n",
                "6. **Image size**: Try 1280 for better accuracy (slower training)\n",
                "\n",
                "### Common Issues:\n",
                "- **Out of memory**: Reduce batch size or image size\n",
                "- **Poor performance**: Check dataset quality, increase epochs, adjust augmentation\n",
                "- **Overfitting**: Increase augmentation, add more training data\n",
                "- **Slow convergence**: Adjust learning rate, check dataset balance\n",
                "\n",
                "### Next Steps:\n",
                "1. Download the trained model (`best.pt`)\n",
                "2. Test on real-world images\n",
                "3. Fine-tune hyperparameters if needed\n",
                "4. Deploy to your application\n",
                "\n",
                "### Resources:\n",
                "- [Ultralytics YOLOv8 Docs](https://docs.ultralytics.com/)\n",
                "- [YOLOv8 Training Tips](https://docs.ultralytics.com/modes/train/)\n",
                "- [Hyperparameter Tuning](https://docs.ultralytics.com/guides/hyperparameter-tuning/)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 4
}